#！/usr/bin/env python
#-*- coding:utf-8 -*-
'''本代码用于把ML数据中每一行补齐，使得每行的字符个数多余128个'''
# seq1 = ['_=','0','list=','ml_sh0']
# seq2 = ['0','ri=','zb0','0f','0gury','0h','0rc','tn=','0','en=','0l0ratiswj0csxycx0d0pqrndajdyf0dp0huclufizhtawu0ek0dl0slq0e0svvdi0oakgfcjuniy0jclo0xevpicvxbmtyqiujofyylnkqp0xlf0m0zo0d0ub','vumadasuescazlft0w0tfikshlhin0b0u0af0jumzeceivputgemdmxyz0gkga','cck','qvmz','v0afztee0hclcljdw0ncvt','h0p0','dz0ieej0n0ddqgwpergkgr0ssbajppqu0igawmpzezu','umlvd0urhn0rdu0','dmn0hywd0t','menxbl0bsplyy0mnp_0dzxvz0ggf0n','k0wxtwpdqyekuxo0xitlibiott0znj0l0afspngy0ptlc0wkwyjqwq0z0zr0jzssxxngf0ujfi0jrcw_yldu0e0r0q0luhreoy0','>','>']
# seq3 = ['b0=','0']
# l = ['0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0']

length = 127
length1 = 128
s=[]
#file = open('data-ML/ML-fanhua-fenci_xssed_unquote_new-yuanshi.txt','r')
file = open('data-ML/ML-fanhua-fenci_normal_unquote_new-yuanshi.txt','r')
for line in file:
    #ls.append(',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\'')
    lines = line.split()
    ls = list(lines)
    for i in ls:
        #s.append(i)
        s.append(i+',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\',\'0\'@')
file.close()
#print(s[0:10])
#f1 = open('data-ML/xssed-zengjia.txt','w')
f1 = open('data-ML/normal-zengjia.txt','w')
for j in s:
    f1.write(j+'\n')
f1.close()
















